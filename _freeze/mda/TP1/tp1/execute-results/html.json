{
  "hash": "c3aa43ee789f88016037d8d4d6670078",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Classification\"\nauthor: \n  - name: \"Martin Bari Garnier\"\n    affiliation: Université Paris-Cité\n    affiliation-url: https://u-paris.fr/\ncitation:\n  url: https://martinbagar.github.io/Master_ISDD_fiches/mda/TP1/tp1.html\n---\n\n\nDans ce TP, l'objectif est d'utiliser des méthodes de classification non-supervisées sur des variables indépendantes de notre jeu de données. Ce dernier contient des poches de protéines décrites par 18 descripteurs, les variables indépendantes.\n\nChargeons les données \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload('../data/X.Rdata')\nx_scaled <- scale(X)\n```\n:::\n\n\n::: {.panel-tabset}\n\n# Raw data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(X, las = 2)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n# Scaled data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(x_scaled, las = 2)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n:::\n\n# Hierarchical classification\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Justifier les méthodes\nmat_dist <- dist(x_scaled, method = \"euclidian\")\nx_classif <- hclust(mat_dist, method = \"ward.D\")\n```\n:::\n\n\nNous utilisons une méthode euclidienne pour la matrice de distance car nous travaillons sur des grandeurs géométriques.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(factoextra)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: ggplot2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n```\n\n\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\n# Détermination du nombre optimal de clusters\nfviz_nbclust(x_scaled, method = \"wss\", FUNcluster=hcut)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Représentation de l'arbre de classification\nplot(x_classif, labels = FALSE)\nrect.hclust(x_classif, k=5)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Récupération des clusters\ncutree(x_classif, k=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1K8Q 3F0R 1PWM 1U30 3IA4 2CL5 1LOX 2IVU 1XM6 2I0E 1RV1 3F1Q 1UDT 1KE6 1GWR 1V4S \n   1    1    2    2    3    4    5    6    2    6    7    3    1    2    1    2 \n1RWQ 1HW8 1SQN 1SQI 1K7F 1OWE 1KVO 1R9O 1QHI 2FB8 1J4I 2AA2 2BR1 1HVR 1HVY 1T46 \n   5    8    1    1    9    8    3    3    5    6    1    1    6    6    7    6 \n1XOZ 1M2Z 1IG3 3D4S 2GH5 2DQ7 1YVF 1VBM 1U4D 1O5R 1QPE 1GKC 2HIW 1RSZ 1YQY 1C14 \n   2    1    2    2    3    6    2   10    6   10    6    5    6    9    4    1 \n1LPZ 1N2V 1UOU 3B68 2I1M 1FK9 1Q41 1M17 2BXR 1JS3 1PMN 2G24 1YWR 1YWN 1R55 3ETR \n  10    9    9    1    6    1    9    6    3   10    3    1    3    6    9    4 \n1UNL 1R58 4COX 1E9X 1E66 1KZN 1O8B 1KTS 1OD8 1GPU 1OLQ 1C9Y 1G7V 1QMF 1F9G 2GSU \n   6   10    1    3    1    6    9    9    5   10    9   10    2    9    8    8 \n3PCM 1HQG 1NNC 1ONZ 1PX4 1AJS 1V16 1G98 1MAI 1D09 1CG0 2GYI 1UCN 1B74 1FTH 1NLJ \n   2   10    2    8   10   10   10   10   10   10    3    4    2    9    8    8 \n1BLS 1QXO 1BMQ 1M0N 1JAK 3JDW 1ICJ 1X9D 1WVC 1KC7 1T03 1MOQ 1EC9 \n   8    3   10    3    5    2    7   10    9   10    7   10   10 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(cutree(x_classif, k=10))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 1  2  3  4  5  6  7  8  9 10 \n15 14 12  4  6 15  4  8 12 19 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nloc <- cmdscale(mat_dist)\nx <- loc[, 1]\ny <- loc[, 2]\n\n## note asp = 1, to ensure Euclidean distances are represented correctly\nplot(x, y, type = \"n\", xlab = \"\", ylab = \"\", asp = 1, axes = FALSE,\n     main = \"cmdscale(eurodist)\")\ntext(x, y, rownames(loc), cex = 0.6)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# kmeans\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clustering des infividus\nx_clust <- kmeans(mat_dist, centers=10)\nplot(x_scaled, col = x_clust$cluster)\npoints(x_clust$centers, col = 1:5, pch = 8)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n## Combien de clusters faut-il faire\n\n## `nstart`\n\n`nstart` permet de choisir le nombre de sets aléatoires de centres à tester. Si nous prenons `nstart = 1`, un seul set aléatoire de centres sera testé. Cela donc générer des clusters différents entre deux réalisation de kmeans. Si nous prenons `nstart = 50`, 50 sets différents seront testés. Ainsi les résultats convergeront vers les mêmes clusters, garantissant une reproductibilité des résultat entre deux itérations. Un équilibre est à trouver en fonction de la taille du jeu de données, pour un petit jeu tel que le nôtre un `nstart = 50` pourrait être trop élevé.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_clust_1 <- kmeans(mat_dist, centers=10, nstart=1)\ntb_1 <- table(x_clust_1$cluster)\n\nx_clust_5 <- kmeans(mat_dist, centers=10, nstart=5)\ntb_5 <- table(x_clust_5$cluster)\n\nx_clust_10 <- kmeans(mat_dist, centers=10, nstart=10)\ntb_10 <- table(x_clust_10$cluster)\n\nx_clust_25 <- kmeans(mat_dist, centers=10, nstart=25)\ntb_25 <- table(x_clust_25$cluster)\n\nx_clust_50 <- kmeans(mat_dist, centers=10, nstart=50)\ntb_50 <- table(x_clust_50$cluster)\n```\n:::\n\n\nDifférentes valeurs de nstart on été testées: 1, 5 10, 25, 50, 100. La répartition étant identique à partir de 5 donc nous allons continuer avec elle.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloc <- cmdscale(mat_dist)\nx <- loc[, 1]\ny <- loc[, 2]\n\n## note asp = 1, to ensure Euclidean distances are represented correctly\nplot(x, y, type = \"n\", xlab = \"\", ylab = \"\", asp = 1, axes = FALSE,\n     main = \"cmdscale(eurodist)\")\ntext(x, y, rownames(loc), cex = 0.6)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clustering des individus final\nplot(x_scaled, col = x_clust_5$cluster)\npoints(x_clust$centers, col = 1:5, pch = 8)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\ncmd\nRecherche du nombre optimal de clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_nbclust(x_scaled, method = \"wss\", FUNcluster=hcut)\n```\n\n::: {.cell-output-display}\n![](tp1_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n# Comparaison classification et clusters\n\n# Classification des descripteurs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmat_cor <- cor(X)\nmat_cor_dist <- as.dist(1 - mat_cor**2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(gplots)\n# heatmap.2(mat_cor_dist, hclustfun=hclust)\n```\n:::",
    "supporting": [
      "tp1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}